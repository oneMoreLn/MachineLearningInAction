{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.Apriori算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1.Ariori算法中的辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    \"\"\"产生简单的数据集\n",
    "    :return: 简单的数据集\n",
    "    \"\"\"\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "def createC1(dataSet):\n",
    "    \"\"\"构建数据集的集合\n",
    "    :param dataSet: 数据集\n",
    "    :return: 不变集\n",
    "    \"\"\"\n",
    "    #创建一个新列表\n",
    "    C1 = []\n",
    "    #遍历数据集中的所有项，得到项的集合\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    #排序\n",
    "    C1.sort()\n",
    "    #使用frozenset，得到不变集\n",
    "    return list(map(frozenset, C1))\n",
    "\n",
    "def scanD(D, Ck, minSupport):\n",
    "    \"\"\"计算支持度，得到满足要求的集合\n",
    "    :param D: 数据集\n",
    "    :param Ck: 集合Ck\n",
    "    :param minSupport: 最小支持度\n",
    "    :return retList: 返回的字典元素的列表\n",
    "    :return supportData: 最频繁集的支持度\n",
    "    \"\"\"\n",
    "    #新建以Ck项为关键词的计数字典\n",
    "    ssCnt = {}\n",
    "    #遍历数据和项的组合\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            #如果项是数据的子集\n",
    "            if can.issubset(tid):\n",
    "                #计数+1，如果以前没统计过就新建一个字典，从1开始\n",
    "                if not ssCnt.__contains__(can): ssCnt[can]=1\n",
    "                else: ssCnt[can] += 1\n",
    "    #数据的个数\n",
    "    numItems = float(len(D))\n",
    "    #新建返回字典构成的列表\n",
    "    retList = []\n",
    "    #支持度字典\n",
    "    supportData = {}\n",
    "    #对于计数器中的每一项\n",
    "    for key in ssCnt:\n",
    "        #计算对应的支持度\n",
    "        support = ssCnt[key]/numItems\n",
    "        #如果支持度大于最小值支持度\n",
    "        if support >= minSupport:\n",
    "            #添加到输出列表中\n",
    "            retList.insert(0,key)\n",
    "        #记录频繁集的支持度\n",
    "        supportData[key] = support\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集：\n",
      "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "第一个候选项集合C1：\n",
      "[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
      "数据集的集合D：\n",
      "[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]\n",
      "结果：\n",
      "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]\n"
     ]
    }
   ],
   "source": [
    "dataSet = loadDataSet()\n",
    "print(f\"数据集：\\n{dataSet}\")\n",
    "\n",
    "C1 = createC1(dataSet)\n",
    "print(f\"第一个候选项集合C1：\\n{C1}\")\n",
    "\n",
    "D = list(map(set, dataSet))\n",
    "print(f\"数据集的集合D：\\n{D}\")\n",
    "\n",
    "L1, suppData0 = scanD(D, C1, 0.5)\n",
    "print(f\"结果：\\n{L1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2.组织完整的Apriori算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lk, k): \n",
    "    \"\"\"产生Ck\n",
    "    :param Lk: 频繁项的集合\n",
    "    :param k: 项集元素的个数\n",
    "    :return retList: 返回Ck的列表\n",
    "    \"\"\"\n",
    "    #新建空的返回列表\n",
    "    retList = []\n",
    "    #Lk的项数\n",
    "    lenLk = len(Lk)\n",
    "    #遍历Lk中项的两两组合\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk): \n",
    "            #为了避免并集后出现重复，只需要合并前k-2个元素相同的集合\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n",
    "            #排序，组合，不考虑元素间的顺序\n",
    "            L1.sort(); L2.sort()\n",
    "            #如果前k-2个元素相同\n",
    "            if L1==L2: \n",
    "                #取并集\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataSet, minSupport = 0.5):\n",
    "    \"\"\"Apriori算法\n",
    "    :param dataSet: 数据集\n",
    "    :param minSupport: 最小支持度，默认0.5\n",
    "    :return L: 满足条件的项集\n",
    "    :return supportData: 最频繁项集的支持度\n",
    "    \"\"\"\n",
    "    #建立C1集和D集\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    #验证C1的超集，留下满足最小支持度的\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    #当还有项时，不断取超集\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终结果为：\n",
      "[[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})], [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})], [frozenset({2, 3, 5})], []]\n"
     ]
    }
   ],
   "source": [
    "L, suppData = apriori(dataSet)\n",
    "print(f\"最终结果为：\\n{L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检验一下，aprioriGen是否真的不会产生重复的项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({2, 5}),\n",
       " frozenset({3, 5}),\n",
       " frozenset({1, 5}),\n",
       " frozenset({2, 3}),\n",
       " frozenset({1, 2}),\n",
       " frozenset({1, 3})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprioriGen(L[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70%的支持度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70%支持度下的最终结果为：\n",
      "[[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []]\n"
     ]
    }
   ],
   "source": [
    "L, _ = apriori(dataSet, minSupport=0.7)\n",
    "print(f\"70%支持度下的最终结果为：\\n{L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.从频繁项集中挖掘关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"生成规则\n",
    "    :param L: 频繁项集合所构成的列表\n",
    "    :param supportData: apriori函数得到的最频繁项集的支持度\n",
    "    :param minConf: 最小置信度，默认0.7\n",
    "    :return bigRuleList: 规则集合\n",
    "    \"\"\"\n",
    "    #新建一个规则列表\n",
    "    bigRuleList = []\n",
    "    #对于含有两个以上项的集合\n",
    "    for i in range(1, len(L)):\n",
    "        #对于每一项\n",
    "        for freqSet in L[i]:\n",
    "            #H1为频繁项对应的不变集组成的列表\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                #生成候选规则集\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                #计算置信度\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"计算置信度\n",
    "    :param freqSet: 频繁集\n",
    "    :param H: 频繁集对应的不变集列表\n",
    "    :param supportData: 支持度\n",
    "    :param brl: 规则列表\n",
    "    :param minConf: 最小置信度，默认值0.7\n",
    "    :return prunedH: 满足最小置信度的规则列表\n",
    "    \"\"\"\n",
    "    #新建一个列表\n",
    "    prunedH = []\n",
    "    #对于频繁集中的每一项\n",
    "    for conseq in H:\n",
    "        #计算置信度\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq]\n",
    "        # 如果置信度满足最小置信度要求\n",
    "        if conf >= minConf: \n",
    "            #打印结果\n",
    "            print(freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            #添加到规则\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"最初项集中生成更多关联规则\n",
    "    :param freqSet: 频繁集合\n",
    "    :param H: 频繁集对应的不变集列表\n",
    "    :param supportData: 支持度\n",
    "    :param brl: 规则列表\n",
    "    :param minConf: 最小置信度，默认值0.7\n",
    "    \"\"\"\n",
    "    #频繁集大小m\n",
    "    m = len(H[0])\n",
    "    #判断频繁集是否可以移除子集\n",
    "    if (len(freqSet) > (m + 1)): \n",
    "        #迭代地取得满足可信度要求的规则\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({1}), frozenset({3}), 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, suppData = apriori(dataSet, minSupport=0.5)\n",
    "rules = generateRules(L, suppData, minConf=0.7)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "降低可信度要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({3}) --> frozenset({2}) conf: 0.6666666666666666\n",
      "frozenset({2}) --> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({5}) --> frozenset({3}) conf: 0.6666666666666666\n",
      "frozenset({3}) --> frozenset({5}) conf: 0.6666666666666666\n",
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "frozenset({3}) --> frozenset({1}) conf: 0.6666666666666666\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n",
      "frozenset({5}) --> frozenset({2, 3}) conf: 0.6666666666666666\n",
      "frozenset({3}) --> frozenset({2, 5}) conf: 0.6666666666666666\n",
      "frozenset({2}) --> frozenset({3, 5}) conf: 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = generateRules(L, suppData, minConf=0.5)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4.发现毒蘑菇的相似特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushDatSet = [line.split() for line in open('mushroom.dat').readlines()]\n",
    "L, suppData = apriori(mushDatSet, minSupport=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'28', '2'})\n",
      "frozenset({'2', '53'})\n",
      "frozenset({'2', '23'})\n",
      "frozenset({'34', '2'})\n",
      "frozenset({'2', '36'})\n",
      "frozenset({'2', '59'})\n",
      "frozenset({'63', '2'})\n",
      "frozenset({'67', '2'})\n",
      "frozenset({'2', '76'})\n",
      "frozenset({'85', '2'})\n",
      "frozenset({'2', '86'})\n",
      "frozenset({'2', '90'})\n",
      "frozenset({'93', '2'})\n",
      "frozenset({'39', '2'})\n",
      "frozenset({'28', '2', '34', '59'})\n",
      "frozenset({'28', '2', '34', '86'})\n",
      "frozenset({'28', '2', '90', '34'})\n",
      "frozenset({'28', '2', '34', '53'})\n",
      "frozenset({'28', '63', '2', '34'})\n",
      "frozenset({'28', '63', '2', '59'})\n",
      "frozenset({'28', '63', '2', '85'})\n",
      "frozenset({'28', '63', '2', '86'})\n",
      "frozenset({'28', '85', '2', '34'})\n",
      "frozenset({'28', '85', '2', '59'})\n",
      "frozenset({'28', '85', '2', '86'})\n",
      "frozenset({'28', '85', '2', '90'})\n",
      "frozenset({'28', '85', '2', '53'})\n",
      "frozenset({'28', '2', '86', '59'})\n",
      "frozenset({'28', '2', '90', '59'})\n",
      "frozenset({'28', '2', '90', '86'})\n",
      "frozenset({'28', '2', '86', '53'})\n",
      "frozenset({'28', '2', '90', '53'})\n",
      "frozenset({'39', '28', '2', '53'})\n",
      "frozenset({'39', '28', '2', '34'})\n",
      "frozenset({'39', '28', '2', '59'})\n",
      "frozenset({'39', '28', '63', '2'})\n",
      "frozenset({'39', '28', '85', '2'})\n",
      "frozenset({'39', '28', '2', '86'})\n",
      "frozenset({'39', '28', '2', '90'})\n",
      "frozenset({'2', '86', '34', '53'})\n",
      "frozenset({'2', '90', '34', '53'})\n",
      "frozenset({'85', '2', '34', '53'})\n",
      "frozenset({'85', '2', '86', '53'})\n",
      "frozenset({'85', '2', '90', '53'})\n",
      "frozenset({'2', '86', '90', '53'})\n",
      "frozenset({'39', '2', '34', '53'})\n",
      "frozenset({'39', '85', '2', '53'})\n",
      "frozenset({'39', '2', '86', '53'})\n",
      "frozenset({'39', '2', '90', '53'})\n",
      "frozenset({'2', '23', '34', '36'})\n",
      "frozenset({'2', '23', '34', '59'})\n",
      "frozenset({'2', '36', '34', '59'})\n",
      "frozenset({'2', '23', '34', '86'})\n",
      "frozenset({'2', '34', '86', '36'})\n",
      "frozenset({'2', '34', '86', '59'})\n",
      "frozenset({'2', '76', '34', '86'})\n",
      "frozenset({'2', '90', '23', '34'})\n",
      "frozenset({'2', '90', '34', '36'})\n",
      "frozenset({'2', '90', '34', '59'})\n",
      "frozenset({'2', '90', '34', '86'})\n",
      "frozenset({'2', '36', '23', '59'})\n",
      "frozenset({'2', '23', '86', '36'})\n",
      "frozenset({'2', '23', '86', '59'})\n",
      "frozenset({'2', '36', '86', '59'})\n",
      "frozenset({'2', '90', '23', '59'})\n",
      "frozenset({'2', '36', '90', '59'})\n",
      "frozenset({'63', '2', '23', '34'})\n",
      "frozenset({'63', '2', '23', '36'})\n",
      "frozenset({'63', '2', '34', '36'})\n",
      "frozenset({'63', '2', '23', '59'})\n",
      "frozenset({'63', '2', '34', '59'})\n",
      "frozenset({'63', '2', '36', '59'})\n",
      "frozenset({'63', '2', '85', '23'})\n",
      "frozenset({'63', '2', '85', '34'})\n",
      "frozenset({'63', '2', '85', '36'})\n",
      "frozenset({'63', '2', '85', '59'})\n",
      "frozenset({'63', '2', '23', '86'})\n",
      "frozenset({'63', '2', '34', '86'})\n",
      "frozenset({'63', '2', '86', '36'})\n",
      "frozenset({'63', '2', '86', '59'})\n",
      "frozenset({'63', '2', '85', '86'})\n",
      "frozenset({'63', '2', '90', '34'})\n",
      "frozenset({'63', '2', '90', '36'})\n",
      "frozenset({'63', '2', '90', '59'})\n",
      "frozenset({'63', '2', '85', '90'})\n",
      "frozenset({'63', '2', '90', '86'})\n",
      "frozenset({'67', '2', '34', '86'})\n",
      "frozenset({'67', '85', '2', '34'})\n",
      "frozenset({'67', '85', '2', '86'})\n",
      "frozenset({'85', '2', '23', '34'})\n",
      "frozenset({'85', '2', '23', '36'})\n",
      "frozenset({'85', '2', '34', '36'})\n",
      "frozenset({'85', '2', '23', '59'})\n",
      "frozenset({'85', '2', '34', '59'})\n",
      "frozenset({'85', '2', '36', '59'})\n",
      "frozenset({'85', '2', '76', '34'})\n",
      "frozenset({'85', '2', '23', '86'})\n",
      "frozenset({'85', '2', '34', '86'})\n",
      "frozenset({'85', '2', '86', '36'})\n",
      "frozenset({'85', '2', '86', '59'})\n",
      "frozenset({'85', '2', '76', '86'})\n",
      "frozenset({'85', '2', '90', '23'})\n",
      "frozenset({'85', '2', '90', '34'})\n",
      "frozenset({'85', '2', '90', '36'})\n",
      "frozenset({'85', '2', '90', '59'})\n",
      "frozenset({'85', '2', '90', '86'})\n",
      "frozenset({'2', '90', '23', '86'})\n",
      "frozenset({'2', '90', '86', '36'})\n",
      "frozenset({'2', '90', '86', '59'})\n",
      "frozenset({'2', '23', '93', '34'})\n",
      "frozenset({'2', '93', '34', '36'})\n",
      "frozenset({'2', '93', '34', '59'})\n",
      "frozenset({'2', '93', '34', '86'})\n",
      "frozenset({'2', '90', '93', '34'})\n",
      "frozenset({'2', '23', '93', '36'})\n",
      "frozenset({'2', '23', '93', '59'})\n",
      "frozenset({'2', '36', '93', '59'})\n",
      "frozenset({'63', '2', '93', '34'})\n",
      "frozenset({'63', '2', '93', '36'})\n",
      "frozenset({'63', '2', '93', '59'})\n",
      "frozenset({'63', '2', '85', '93'})\n",
      "frozenset({'63', '2', '93', '86'})\n",
      "frozenset({'63', '2', '90', '93'})\n",
      "frozenset({'85', '2', '23', '93'})\n",
      "frozenset({'85', '2', '93', '34'})\n",
      "frozenset({'85', '2', '93', '36'})\n",
      "frozenset({'85', '2', '93', '59'})\n",
      "frozenset({'85', '2', '93', '86'})\n",
      "frozenset({'85', '2', '90', '93'})\n",
      "frozenset({'2', '23', '93', '86'})\n",
      "frozenset({'2', '93', '86', '36'})\n",
      "frozenset({'2', '93', '86', '59'})\n",
      "frozenset({'2', '90', '23', '93'})\n",
      "frozenset({'2', '90', '93', '36'})\n",
      "frozenset({'2', '90', '93', '59'})\n",
      "frozenset({'2', '90', '93', '86'})\n",
      "frozenset({'39', '2', '23', '34'})\n",
      "frozenset({'39', '2', '34', '36'})\n",
      "frozenset({'39', '2', '34', '59'})\n",
      "frozenset({'39', '2', '76', '34'})\n",
      "frozenset({'39', '2', '34', '86'})\n",
      "frozenset({'39', '2', '90', '34'})\n",
      "frozenset({'39', '2', '23', '36'})\n",
      "frozenset({'39', '2', '23', '59'})\n",
      "frozenset({'39', '2', '36', '59'})\n",
      "frozenset({'39', '63', '2', '23'})\n",
      "frozenset({'39', '63', '2', '34'})\n",
      "frozenset({'39', '63', '2', '36'})\n",
      "frozenset({'39', '63', '2', '59'})\n",
      "frozenset({'39', '63', '2', '85'})\n",
      "frozenset({'39', '63', '2', '86'})\n",
      "frozenset({'39', '63', '2', '90'})\n",
      "frozenset({'39', '67', '2', '34'})\n",
      "frozenset({'39', '67', '85', '2'})\n",
      "frozenset({'39', '67', '2', '86'})\n",
      "frozenset({'39', '85', '2', '23'})\n",
      "frozenset({'39', '85', '2', '34'})\n",
      "frozenset({'39', '85', '2', '36'})\n",
      "frozenset({'39', '85', '2', '59'})\n",
      "frozenset({'39', '85', '2', '76'})\n",
      "frozenset({'39', '85', '2', '86'})\n",
      "frozenset({'39', '85', '2', '90'})\n",
      "frozenset({'39', '2', '23', '86'})\n",
      "frozenset({'39', '2', '86', '36'})\n",
      "frozenset({'39', '2', '86', '59'})\n",
      "frozenset({'39', '2', '76', '86'})\n",
      "frozenset({'39', '2', '90', '36'})\n",
      "frozenset({'39', '2', '90', '59'})\n",
      "frozenset({'39', '2', '90', '86'})\n",
      "frozenset({'39', '2', '23', '93'})\n",
      "frozenset({'39', '2', '93', '34'})\n",
      "frozenset({'39', '2', '93', '36'})\n",
      "frozenset({'39', '2', '93', '59'})\n",
      "frozenset({'39', '63', '2', '93'})\n",
      "frozenset({'39', '85', '2', '93'})\n",
      "frozenset({'39', '2', '93', '86'})\n",
      "frozenset({'39', '2', '90', '93'})\n"
     ]
    }
   ],
   "source": [
    "for item in L[1]:\n",
    "    if item.intersection('2'): print(item)\n",
    "for item in L[3]:\n",
    "    if item.intersection('2'): print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
